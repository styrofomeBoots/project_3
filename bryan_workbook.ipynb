{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import requests\n",
    "import time\n",
    "import sqlite3\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint as pp\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_curve, roc_auc_score, f1_score, precision_recall_curve, average_precision_score, auc\n",
    "from sklearn.svm import SVC, SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from matplotlib import pyplot\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>director_name</th>\n",
       "      <th>num_critic_for_reviews</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_facebook_likes</th>\n",
       "      <th>actor_3_facebook_likes</th>\n",
       "      <th>actor_2_name</th>\n",
       "      <th>actor_1_facebook_likes</th>\n",
       "      <th>gross</th>\n",
       "      <th>genres</th>\n",
       "      <th>...</th>\n",
       "      <th>actor_3_score</th>\n",
       "      <th>imdb_num_code</th>\n",
       "      <th>release_date</th>\n",
       "      <th>success_bins</th>\n",
       "      <th>production_companies_count</th>\n",
       "      <th>genres_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>total_actor_starpower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Color</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>723.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>760505847.0</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066294</td>\n",
       "      <td>tt0499549</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>extreme success</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>185.070892</td>\n",
       "      <td>12114.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.334665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Color</td>\n",
       "      <td>Stephen Sommers</td>\n",
       "      <td>106.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Jason Flemyng</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>11146409.0</td>\n",
       "      <td>Action|Adventure|Horror|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066294</td>\n",
       "      <td>tt0118956</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>no success</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.922458</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.933174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Color</td>\n",
       "      <td>Terrence Malick</td>\n",
       "      <td>222.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Michael Greyeyes</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>12712093.0</td>\n",
       "      <td>Biography|Drama|History|Romance</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066294</td>\n",
       "      <td>tt0402399</td>\n",
       "      <td>2005-12-25</td>\n",
       "      <td>no success</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.694502</td>\n",
       "      <td>336.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>11.013046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Color</td>\n",
       "      <td>Brian Robbins</td>\n",
       "      <td>76.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Joel David Moore</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>61112916.0</td>\n",
       "      <td>Comedy|Family|Fantasy</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066294</td>\n",
       "      <td>tt0393735</td>\n",
       "      <td>2006-03-09</td>\n",
       "      <td>moderate success</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.878907</td>\n",
       "      <td>138.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.698882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Color</td>\n",
       "      <td>Brad Peyton</td>\n",
       "      <td>178.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>722.0</td>\n",
       "      <td>Dwayne Johnson</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>103812241.0</td>\n",
       "      <td>Action|Adventure|Comedy|Family|Fantasy|Sci-Fi</td>\n",
       "      <td>...</td>\n",
       "      <td>2.066294</td>\n",
       "      <td>tt1397514</td>\n",
       "      <td>2012-01-19</td>\n",
       "      <td>average success</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.46307</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.475240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   color    director_name  num_critic_for_reviews  duration  \\\n",
       "0  Color    James Cameron                   723.0     178.0   \n",
       "1  Color  Stephen Sommers                   106.0     106.0   \n",
       "2  Color  Terrence Malick                   222.0     150.0   \n",
       "3  Color    Brian Robbins                    76.0      98.0   \n",
       "4  Color      Brad Peyton                   178.0      94.0   \n",
       "\n",
       "   director_facebook_likes  actor_3_facebook_likes      actor_2_name  \\\n",
       "0                      0.0                   855.0  Joel David Moore   \n",
       "1                    208.0                   855.0     Jason Flemyng   \n",
       "2                      0.0                   855.0  Michael Greyeyes   \n",
       "3                     48.0                   722.0  Joel David Moore   \n",
       "4                     62.0                   722.0    Dwayne Johnson   \n",
       "\n",
       "   actor_1_facebook_likes        gross  \\\n",
       "0                  1000.0  760505847.0   \n",
       "1                  3000.0   11146409.0   \n",
       "2                 23000.0   12712093.0   \n",
       "3                 21000.0   61112916.0   \n",
       "4                 14000.0  103812241.0   \n",
       "\n",
       "                                          genres          ...           \\\n",
       "0                Action|Adventure|Fantasy|Sci-Fi          ...            \n",
       "1                 Action|Adventure|Horror|Sci-Fi          ...            \n",
       "2                Biography|Drama|History|Romance          ...            \n",
       "3                          Comedy|Family|Fantasy          ...            \n",
       "4  Action|Adventure|Comedy|Family|Fantasy|Sci-Fi          ...            \n",
       "\n",
       "  actor_3_score imdb_num_code  release_date      success_bins  \\\n",
       "0      2.066294     tt0499549    2009-12-10   extreme success   \n",
       "1      2.066294     tt0118956    1998-01-30        no success   \n",
       "2      2.066294     tt0402399    2005-12-25        no success   \n",
       "3      2.066294     tt0393735    2006-03-09  moderate success   \n",
       "4      2.066294     tt1397514    2012-01-19   average success   \n",
       "\n",
       "  production_companies_count  genres_count  popularity vote_count  \\\n",
       "0                        4.0             4  185.070892    12114.0   \n",
       "1                        3.0             4    6.922458      155.0   \n",
       "2                        5.0             3    7.694502      336.0   \n",
       "3                        3.0             2    4.878907      138.0   \n",
       "4                        3.0             3     9.46307     1050.0   \n",
       "\n",
       "   vote_average total_actor_starpower  \n",
       "0           7.2              5.334665  \n",
       "1           6.0             10.933174  \n",
       "2           6.4             11.013046  \n",
       "3           4.5             13.698882  \n",
       "4           5.8              6.475240  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create connection to database\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "con = sqlite3.connect(\"db/movies.db\")\n",
    "sql = f\"\"\"\n",
    "   SELECT * FROM movie_data\n",
    "   \"\"\"\n",
    "\n",
    "# bring in db to pandas dataframe\n",
    "movieDf = pd.read_sql(sql, con)\n",
    "movieDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actor_1_facebook_likes\n",
      "actor_1_name\n",
      "actor_1_score\n",
      "actor_2_facebook_likes\n",
      "actor_2_name\n",
      "actor_2_score\n",
      "actor_3_facebook_likes\n",
      "actor_3_name\n",
      "actor_3_score\n",
      "aspect_ratio\n",
      "budget\n",
      "cast_total_facebook_likes\n",
      "color\n",
      "content_rating\n",
      "country\n",
      "director_facebook_likes\n",
      "director_name\n",
      "director_score\n",
      "duration\n",
      "facenumber_in_poster\n",
      "genres\n",
      "genres_count\n",
      "gross\n",
      "gross_margin\n",
      "imdb_num_code\n",
      "imdb_score\n",
      "language\n",
      "movie_facebook_likes\n",
      "movie_imdb_link\n",
      "movie_title\n",
      "num_critic_for_reviews\n",
      "num_user_for_reviews\n",
      "num_voted_users\n",
      "plot_keywords\n",
      "popularity\n",
      "production_companies_count\n",
      "rating_numeric\n",
      "release_date\n",
      "revenue\n",
      "success_bins\n",
      "successful\n",
      "title_year\n",
      "total_actor_starpower\n",
      "vote_average\n",
      "vote_count\n"
     ]
    }
   ],
   "source": [
    "# review columns\n",
    "for col in movieDf.columns.sort_values().values:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>facenumber_in_poster</th>\n",
       "      <th>rating_numeric</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "      <th>gross_margin</th>\n",
       "      <th>successful</th>\n",
       "      <th>director_score</th>\n",
       "      <th>production_companies_count</th>\n",
       "      <th>total_actor_starpower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>237000000.0</td>\n",
       "      <td>523505847.0</td>\n",
       "      <td>0.688365</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091853</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.334665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>45000000.0</td>\n",
       "      <td>-33853591.0</td>\n",
       "      <td>-3.037175</td>\n",
       "      <td>0</td>\n",
       "      <td>1.766773</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.933174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>-17287907.0</td>\n",
       "      <td>-1.359958</td>\n",
       "      <td>0</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.013046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>11112916.0</td>\n",
       "      <td>0.181842</td>\n",
       "      <td>1</td>\n",
       "      <td>2.650160</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.698882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>79000000.0</td>\n",
       "      <td>24812241.0</td>\n",
       "      <td>0.239011</td>\n",
       "      <td>1</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.475240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>-4671063.0</td>\n",
       "      <td>-0.048999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.409212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>-6139597.0</td>\n",
       "      <td>-0.325528</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.816560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>83000000.0</td>\n",
       "      <td>-16137932.0</td>\n",
       "      <td>-0.241362</td>\n",
       "      <td>0</td>\n",
       "      <td>2.208466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.499734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>42000000.0</td>\n",
       "      <td>-28791977.0</td>\n",
       "      <td>-2.179885</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.409212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>45000000.0</td>\n",
       "      <td>25001065.0</td>\n",
       "      <td>0.357153</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.409212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>-10043599.0</td>\n",
       "      <td>-2.026390</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.483759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>189.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>60000000.0</td>\n",
       "      <td>76801374.0</td>\n",
       "      <td>0.561408</td>\n",
       "      <td>1</td>\n",
       "      <td>1.766773</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.355964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>21629916.0</td>\n",
       "      <td>0.878197</td>\n",
       "      <td>1</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.917199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>96.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>-5628919.0</td>\n",
       "      <td>-15.168977</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.172524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>-14821835.0</td>\n",
       "      <td>-0.588678</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.035144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>209000000.0</td>\n",
       "      <td>-8930592.0</td>\n",
       "      <td>-0.044637</td>\n",
       "      <td>0</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.031949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60000000.0</td>\n",
       "      <td>-9181250.0</td>\n",
       "      <td>-0.180667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.300319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>-890722.0</td>\n",
       "      <td>-0.246787</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650160</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.122204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>50000000.0</td>\n",
       "      <td>7168.0</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>1</td>\n",
       "      <td>8.392173</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.230032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>46000000.0</td>\n",
       "      <td>12918501.0</td>\n",
       "      <td>0.219261</td>\n",
       "      <td>1</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.656017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>-1140525.0</td>\n",
       "      <td>-0.234701</td>\n",
       "      <td>0</td>\n",
       "      <td>1.766773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.887114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>128.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>82000000.0</td>\n",
       "      <td>-45618284.0</td>\n",
       "      <td>-1.253879</td>\n",
       "      <td>0</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.986155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>23500000.0</td>\n",
       "      <td>-12803790.0</td>\n",
       "      <td>-1.197040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.082268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>140000000.0</td>\n",
       "      <td>58539855.0</td>\n",
       "      <td>0.294852</td>\n",
       "      <td>1</td>\n",
       "      <td>5.742013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.818158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>34000000.0</td>\n",
       "      <td>20132596.0</td>\n",
       "      <td>0.371913</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.653088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>157.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>68000000.0</td>\n",
       "      <td>-39034803.0</td>\n",
       "      <td>-1.347645</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650160</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.192758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>35003492.0</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>1</td>\n",
       "      <td>2.650160</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.957401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>118.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>53000000.0</td>\n",
       "      <td>2808744.0</td>\n",
       "      <td>0.050328</td>\n",
       "      <td>1</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.726305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>121.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>84031112.0</td>\n",
       "      <td>0.456614</td>\n",
       "      <td>1</td>\n",
       "      <td>5.300319</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.440895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>90000000.0</td>\n",
       "      <td>160147615.0</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>1</td>\n",
       "      <td>3.091853</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.096379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>110000000.0</td>\n",
       "      <td>3330342.0</td>\n",
       "      <td>0.029386</td>\n",
       "      <td>1</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.509851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>149000000.0</td>\n",
       "      <td>-84540684.0</td>\n",
       "      <td>-1.311536</td>\n",
       "      <td>0</td>\n",
       "      <td>1.766773</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.333067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>94.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>2828771.0</td>\n",
       "      <td>0.320404</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.710596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>68000000.0</td>\n",
       "      <td>13257500.0</td>\n",
       "      <td>0.163154</td>\n",
       "      <td>1</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.601970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>136.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>2615685.0</td>\n",
       "      <td>0.061378</td>\n",
       "      <td>1</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.106763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>160000000.0</td>\n",
       "      <td>132568851.0</td>\n",
       "      <td>0.453120</td>\n",
       "      <td>1</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.526624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>250000000.0</td>\n",
       "      <td>198130642.0</td>\n",
       "      <td>0.442127</td>\n",
       "      <td>1</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.711928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135000000.0</td>\n",
       "      <td>48635922.0</td>\n",
       "      <td>0.264850</td>\n",
       "      <td>1</td>\n",
       "      <td>2.208466</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.904153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>53500000.0</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>1</td>\n",
       "      <td>1.766773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.337593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>109.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>41489425.0</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.123536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>106.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>70000000.0</td>\n",
       "      <td>-32245792.0</td>\n",
       "      <td>-0.854098</td>\n",
       "      <td>0</td>\n",
       "      <td>7.067093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.585729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>107.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>32000000.0</td>\n",
       "      <td>-13363463.0</td>\n",
       "      <td>-0.717057</td>\n",
       "      <td>0</td>\n",
       "      <td>5.300319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.944089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7000000.0</td>\n",
       "      <td>1373585.0</td>\n",
       "      <td>0.164038</td>\n",
       "      <td>1</td>\n",
       "      <td>7.067093</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.505325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>128.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>70000000.0</td>\n",
       "      <td>-30619558.0</td>\n",
       "      <td>-0.777532</td>\n",
       "      <td>0</td>\n",
       "      <td>7.508786</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.526624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13500000.0</td>\n",
       "      <td>2354988.0</td>\n",
       "      <td>0.148533</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.650160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>121.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>11605861.0</td>\n",
       "      <td>0.659204</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.134984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>143.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>105000000.0</td>\n",
       "      <td>39812796.0</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>1</td>\n",
       "      <td>2.208466</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.109159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>116.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75000000.0</td>\n",
       "      <td>-29565557.0</td>\n",
       "      <td>-0.650730</td>\n",
       "      <td>0</td>\n",
       "      <td>3.533546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.475240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>-16601608.0</td>\n",
       "      <td>-3.774472</td>\n",
       "      <td>0</td>\n",
       "      <td>2.650160</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.789404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>45000000.0</td>\n",
       "      <td>-44854891.0</td>\n",
       "      <td>-309.111709</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3.029020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>31838728.0</td>\n",
       "      <td>0.687087</td>\n",
       "      <td>1</td>\n",
       "      <td>2.208466</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.274228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>150000000.0</td>\n",
       "      <td>56435493.0</td>\n",
       "      <td>0.273381</td>\n",
       "      <td>1</td>\n",
       "      <td>2.208466</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.773695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>27919096.0</td>\n",
       "      <td>0.650505</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.891374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31000000.0</td>\n",
       "      <td>62749203.0</td>\n",
       "      <td>0.669331</td>\n",
       "      <td>1</td>\n",
       "      <td>5.742013</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.656017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>-2533006.0</td>\n",
       "      <td>-0.112743</td>\n",
       "      <td>0</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.007455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15000000.0</td>\n",
       "      <td>13637507.0</td>\n",
       "      <td>0.476211</td>\n",
       "      <td>1</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.400692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>8000000.0</td>\n",
       "      <td>279017.0</td>\n",
       "      <td>0.033702</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883387</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.486954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>114.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>92000000.0</td>\n",
       "      <td>-91973129.0</td>\n",
       "      <td>-3422.765398</td>\n",
       "      <td>0</td>\n",
       "      <td>5.300319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.694622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>55720716.0</td>\n",
       "      <td>0.582118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.325080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.502396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>52000000.0</td>\n",
       "      <td>112435221.0</td>\n",
       "      <td>0.683766</td>\n",
       "      <td>1</td>\n",
       "      <td>11.042332</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.691693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    duration  facenumber_in_poster  rating_numeric       budget      revenue  \\\n",
       "0      178.0                   0.0               3  237000000.0  523505847.0   \n",
       "1      106.0                   0.0               4   45000000.0  -33853591.0   \n",
       "2      150.0                   0.0               3   30000000.0  -17287907.0   \n",
       "3       98.0                   0.0               2   50000000.0   11112916.0   \n",
       "4       94.0                   3.0               2   79000000.0   24812241.0   \n",
       "5      146.0                   4.0               4  100000000.0   -4671063.0   \n",
       "6       90.0                   0.0               3   25000000.0   -6139597.0   \n",
       "7      121.0                   0.0               4   83000000.0  -16137932.0   \n",
       "8      101.0                   1.0               4   42000000.0  -28791977.0   \n",
       "9      110.0                   1.0               4   45000000.0   25001065.0   \n",
       "10     120.0                   2.0               3   15000000.0  -10043599.0   \n",
       "11     189.0                   0.0               4   60000000.0   76801374.0   \n",
       "12      98.0                   0.0               2    3000000.0   21629916.0   \n",
       "13      96.0                   2.0               3    6000000.0   -5628919.0   \n",
       "14     119.0                   1.0               3   40000000.0  -14821835.0   \n",
       "15     169.0                   0.0               3  209000000.0   -8930592.0   \n",
       "16      93.0                   0.0               1   60000000.0   -9181250.0   \n",
       "17     102.0                   0.0               4    4500000.0    -890722.0   \n",
       "18     121.0                   0.0               4   50000000.0       7168.0   \n",
       "19     116.0                   1.0               4   46000000.0   12918501.0   \n",
       "20      90.0                   0.0               4    6000000.0   -1140525.0   \n",
       "21     128.0                   4.0               3   82000000.0  -45618284.0   \n",
       "22     104.0                   0.0               3   23500000.0  -12803790.0   \n",
       "23     184.0                   0.0               3  140000000.0   58539855.0   \n",
       "24      87.0                   0.0               2   34000000.0   20132596.0   \n",
       "25     157.0                   1.0               4   68000000.0  -39034803.0   \n",
       "26     120.0                   0.0               4   65000000.0   35003492.0   \n",
       "27     118.0                   4.0               3   53000000.0    2808744.0   \n",
       "28     121.0                   4.0               3  100000000.0   84031112.0   \n",
       "29      98.0                   0.0               3   90000000.0  160147615.0   \n",
       "..       ...                   ...             ...          ...          ...   \n",
       "70     142.0                   1.0               4  110000000.0    3330342.0   \n",
       "71      85.0                   0.0               2  149000000.0  -84540684.0   \n",
       "72      94.0                  10.0               4    6000000.0    2828771.0   \n",
       "73     125.0                   0.0               4   68000000.0   13257500.0   \n",
       "74     136.0                   3.0               4   40000000.0    2615685.0   \n",
       "75     148.0                   0.0               3  160000000.0  132568851.0   \n",
       "76     164.0                   0.0               3  250000000.0  198130642.0   \n",
       "77     156.0                   0.0               4  135000000.0   48635922.0   \n",
       "78     112.0                   1.0               4   12000000.0   53500000.0   \n",
       "79     109.0                   3.0               4   25000000.0   41489425.0   \n",
       "80     106.0                   3.0               3   70000000.0  -32245792.0   \n",
       "81     107.0                   0.0               4   32000000.0  -13363463.0   \n",
       "82     164.0                   0.0               4    7000000.0    1373585.0   \n",
       "83     128.0                   1.0               4   70000000.0  -30619558.0   \n",
       "84     107.0                   2.0               3   13500000.0    2354988.0   \n",
       "85     121.0                   1.0               4    6000000.0   11605861.0   \n",
       "86     143.0                   4.0               3  105000000.0   39812796.0   \n",
       "87     116.0                   2.0               3   75000000.0  -29565557.0   \n",
       "88     145.0                   1.0               4   21000000.0  -16601608.0   \n",
       "89      45.0                   1.0               0   45000000.0  -44854891.0   \n",
       "90     120.0                   2.0               3   14500000.0   31838728.0   \n",
       "91     111.0                   0.0               1  150000000.0   56435493.0   \n",
       "92     112.0                   1.0               3   15000000.0   27919096.0   \n",
       "93     138.0                   0.0               4   31000000.0   62749203.0   \n",
       "94     103.0                   0.0               4   25000000.0   -2533006.0   \n",
       "95     100.0                   1.0               4   15000000.0   13637507.0   \n",
       "96      92.0                   1.0               4    8000000.0     279017.0   \n",
       "97     114.0                   2.0               4   92000000.0  -91973129.0   \n",
       "98     157.0                   0.0               4   40000000.0   55720716.0   \n",
       "99     141.0                   0.0               3   52000000.0  112435221.0   \n",
       "\n",
       "    gross_margin  successful  director_score  production_companies_count  \\\n",
       "0       0.688365           1        3.091853                         4.0   \n",
       "1      -3.037175           0        1.766773                         3.0   \n",
       "2      -1.359958           0        1.325080                         5.0   \n",
       "3       0.181842           1        2.650160                         3.0   \n",
       "4       0.239011           1        1.325080                         3.0   \n",
       "5      -0.048999           0        0.441693                         4.0   \n",
       "6      -0.325528           0        2.650160                         1.0   \n",
       "7      -0.241362           0        2.208466                         1.0   \n",
       "8      -2.179885           0        0.883387                         8.0   \n",
       "9       0.357153           1        0.883387                         4.0   \n",
       "10     -2.026390           0        0.441693                         4.0   \n",
       "11      0.561408           1        1.766773                         3.0   \n",
       "12      0.878197           1        1.325080                         1.0   \n",
       "13    -15.168977           0        0.441693                         4.0   \n",
       "14     -0.588678           0        0.441693                         2.0   \n",
       "15     -0.044637           0        3.533546                         4.0   \n",
       "16     -0.180667           0        0.441693                         1.0   \n",
       "17     -0.246787           0        2.650160                         1.0   \n",
       "18      0.000143           1        8.392173                         3.0   \n",
       "19      0.219261           1        3.533546                         2.0   \n",
       "20     -0.234701           0        1.766773                         1.0   \n",
       "21     -1.253879           0        3.533546                         4.0   \n",
       "22     -1.197040           0        0.441693                         1.0   \n",
       "23      0.294852           1        5.742013                         2.0   \n",
       "24      0.371913           1        0.883387                         5.0   \n",
       "25     -1.347645           0        2.650160                         5.0   \n",
       "26      0.350023           1        2.650160                         4.0   \n",
       "27      0.050328           1        3.533546                         4.0   \n",
       "28      0.456614           1        5.300319                         2.0   \n",
       "29      0.640212           1        3.091853                         3.0   \n",
       "..           ...         ...             ...                         ...   \n",
       "70      0.029386           1        3.533546                         4.0   \n",
       "71     -1.311536           0        1.766773                         2.0   \n",
       "72      0.320404           1        0.883387                         5.0   \n",
       "73      0.163154           1        1.325080                         5.0   \n",
       "74      0.061378           1        1.325080                         4.0   \n",
       "75      0.453120           1        3.533546                         3.0   \n",
       "76      0.442127           1        3.533546                         4.0   \n",
       "77      0.264850           1        2.208466                         9.0   \n",
       "78      0.816794           1        1.766773                         1.0   \n",
       "79      0.624000           1        1.325080                         9.0   \n",
       "80     -0.854098           0        7.067093                         1.0   \n",
       "81     -0.717057           0        5.300319                         1.0   \n",
       "82      0.164038           1        7.067093                         2.0   \n",
       "83     -0.777532           0        7.508786                         3.0   \n",
       "84      0.148533           1        0.883387                         1.0   \n",
       "85      0.659204           1        0.441693                         8.0   \n",
       "86      0.274926           1        2.208466                         6.0   \n",
       "87     -0.650730           0        3.533546                         4.0   \n",
       "88     -3.774472           0        2.650160                        17.0   \n",
       "89   -309.111709           0        0.441693                        25.0   \n",
       "90      0.687087           1        2.208466                         2.0   \n",
       "91      0.273381           1        2.208466                         2.0   \n",
       "92      0.650505           1        0.883387                         5.0   \n",
       "93      0.669331           1        5.742013                         3.0   \n",
       "94     -0.112743           0        0.441693                         6.0   \n",
       "95      0.476211           1        0.441693                         6.0   \n",
       "96      0.033702           1        0.883387                         1.0   \n",
       "97  -3422.765398           0        5.300319                         6.0   \n",
       "98      0.582118           1        1.325080                         3.0   \n",
       "99      0.683766           1       11.042332                         4.0   \n",
       "\n",
       "    total_actor_starpower  \n",
       "0                5.334665  \n",
       "1               10.933174  \n",
       "2               11.013046  \n",
       "3               13.698882  \n",
       "4                6.475240  \n",
       "5                3.409212  \n",
       "6                2.816560  \n",
       "7                6.499734  \n",
       "8                3.409212  \n",
       "9                3.409212  \n",
       "10              14.483759  \n",
       "11              12.355964  \n",
       "12               5.917199  \n",
       "13              15.172524  \n",
       "14              20.035144  \n",
       "15              14.031949  \n",
       "16               4.300319  \n",
       "17               5.122204  \n",
       "18              10.230032  \n",
       "19              17.656017  \n",
       "20               8.887114  \n",
       "21               6.986155  \n",
       "22               7.082268  \n",
       "23               7.818158  \n",
       "24               6.653088  \n",
       "25              11.192758  \n",
       "26              15.957401  \n",
       "27              11.726305  \n",
       "28               5.440895  \n",
       "29              12.096379  \n",
       "..                    ...  \n",
       "70               6.509851  \n",
       "71              13.333067  \n",
       "72              14.710596  \n",
       "73              23.601970  \n",
       "74              20.106763  \n",
       "75              10.526624  \n",
       "76               7.711928  \n",
       "77              11.904153  \n",
       "78              16.337593  \n",
       "79              15.123536  \n",
       "80              10.585729  \n",
       "81               9.944089  \n",
       "82               3.505325  \n",
       "83              10.526624  \n",
       "84               8.650160  \n",
       "85               4.134984  \n",
       "86              11.109159  \n",
       "87               6.475240  \n",
       "88               3.789404  \n",
       "89               3.029020  \n",
       "90              12.274228  \n",
       "91               6.773695  \n",
       "92              12.891374  \n",
       "93              17.656017  \n",
       "94              14.007455  \n",
       "95               8.400692  \n",
       "96               7.486954  \n",
       "97               9.694622  \n",
       "98               5.502396  \n",
       "99              11.691693  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table for model purposes\n",
    "modelDf = movieDf[[\"duration\",\"facenumber_in_poster\",\"rating_numeric\",\"budget\",\"revenue\",\"gross_margin\", \n",
    "                   \"successful\",\"director_score\",\"production_companies_count\",\"total_actor_starpower\"]]\n",
    "modelDf = modelDf.dropna()\n",
    "modelDf.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1950\n",
       "0    1687\n",
       "Name: successful, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDf[\"successful\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3637, 4) (3637, 1)\n"
     ]
    }
   ],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = modelDf[[\"rating_numeric\",\"director_score\",\"production_companies_count\",\"total_actor_starpower\"]]\n",
    "y = modelDf[\"successful\"].values.reshape(-1, 1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1158, train_size=0.85, stratify=y)\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    293\n",
       "0    253\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build logistic model \n",
    "model = LogisticRegression()\n",
    "\n",
    "#fit on training data\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing_score: 0.5586080586080586\n"
     ]
    }
   ],
   "source": [
    "# Use our model to predict a value\n",
    "predicted = model.predict(X_test_scaled)\n",
    "\n",
    "# Score the prediction with mse and r2\n",
    "mse = mean_squared_error(y_test, predicted)\n",
    "r2 = r2_score(y_test, predicted)\n",
    "testing_score = model.score(X_test_scaled,y_test)\n",
    "\n",
    "print(f\"testing_score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the empty squential network\n",
    "modelNN = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Add the first layer where the input dimensions are the 3 columns of the training data\n",
    "modelNN.add(Dense(units=16, activation='relu', input_dim=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the hidden layer\n",
    "modelNN.add(Dense(units=16, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer, 2 units for \"classes\" of output, i.e. Yes or No \n",
    "modelNN.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using the adaptive learning rate optimizer \"adam\", spare_categorical_crossentropy\n",
    "# for the loss function since we did not one-hot encode the labels and used accuracy for the training metrics.\n",
    "modelNN.compile(optimizer='adadelta',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 0s - loss: 0.7067 - acc: 0.4824\n",
      "Epoch 2/200\n",
      " - 0s - loss: 0.6866 - acc: 0.5429\n",
      "Epoch 3/200\n",
      " - 0s - loss: 0.6813 - acc: 0.5645\n",
      "Epoch 4/200\n",
      " - 0s - loss: 0.6789 - acc: 0.5623\n",
      "Epoch 5/200\n",
      " - 0s - loss: 0.6772 - acc: 0.5658\n",
      "Epoch 6/200\n",
      " - 0s - loss: 0.6752 - acc: 0.5797\n",
      "Epoch 7/200\n",
      " - 0s - loss: 0.6750 - acc: 0.5733\n",
      "Epoch 8/200\n",
      " - 0s - loss: 0.6734 - acc: 0.5794\n",
      "Epoch 9/200\n",
      " - 0s - loss: 0.6737 - acc: 0.5730\n",
      "Epoch 10/200\n",
      " - 0s - loss: 0.6717 - acc: 0.5797\n",
      "Epoch 11/200\n",
      " - 0s - loss: 0.6726 - acc: 0.5755\n",
      "Epoch 12/200\n",
      " - 0s - loss: 0.6714 - acc: 0.5739\n",
      "Epoch 13/200\n",
      " - 0s - loss: 0.6713 - acc: 0.5781\n",
      "Epoch 14/200\n",
      " - 0s - loss: 0.6708 - acc: 0.5723\n",
      "Epoch 15/200\n",
      " - 0s - loss: 0.6704 - acc: 0.5794\n",
      "Epoch 16/200\n",
      " - 0s - loss: 0.6701 - acc: 0.5791\n",
      "Epoch 17/200\n",
      " - 0s - loss: 0.6697 - acc: 0.5778\n",
      "Epoch 18/200\n",
      " - 0s - loss: 0.6697 - acc: 0.5742\n",
      "Epoch 19/200\n",
      " - 0s - loss: 0.6693 - acc: 0.5778\n",
      "Epoch 20/200\n",
      " - 0s - loss: 0.6695 - acc: 0.5836\n",
      "Epoch 21/200\n",
      " - 0s - loss: 0.6687 - acc: 0.5904\n",
      "Epoch 22/200\n",
      " - 0s - loss: 0.6683 - acc: 0.5823\n",
      "Epoch 23/200\n",
      " - 0s - loss: 0.6682 - acc: 0.5791\n",
      "Epoch 24/200\n",
      " - 0s - loss: 0.6681 - acc: 0.5878\n",
      "Epoch 25/200\n",
      " - 0s - loss: 0.6675 - acc: 0.5878\n",
      "Epoch 26/200\n",
      " - 0s - loss: 0.6673 - acc: 0.5794\n",
      "Epoch 27/200\n",
      " - 0s - loss: 0.6670 - acc: 0.5901\n",
      "Epoch 28/200\n",
      " - 0s - loss: 0.6673 - acc: 0.5875\n",
      "Epoch 29/200\n",
      " - 0s - loss: 0.6663 - acc: 0.5937\n",
      "Epoch 30/200\n",
      " - 0s - loss: 0.6668 - acc: 0.5810\n",
      "Epoch 31/200\n",
      " - 0s - loss: 0.6658 - acc: 0.5904\n",
      "Epoch 32/200\n",
      " - 0s - loss: 0.6661 - acc: 0.5875\n",
      "Epoch 33/200\n",
      " - 0s - loss: 0.6659 - acc: 0.5865\n",
      "Epoch 34/200\n",
      " - 0s - loss: 0.6657 - acc: 0.5859\n",
      "Epoch 35/200\n",
      " - 0s - loss: 0.6657 - acc: 0.5862\n",
      "Epoch 36/200\n",
      " - 0s - loss: 0.6654 - acc: 0.5865\n",
      "Epoch 37/200\n",
      " - 0s - loss: 0.6654 - acc: 0.5843\n",
      "Epoch 38/200\n",
      " - 0s - loss: 0.6647 - acc: 0.5878\n",
      "Epoch 39/200\n",
      " - 0s - loss: 0.6647 - acc: 0.5882\n",
      "Epoch 40/200\n",
      " - 0s - loss: 0.6652 - acc: 0.5869\n",
      "Epoch 41/200\n",
      " - 0s - loss: 0.6649 - acc: 0.5895\n",
      "Epoch 42/200\n",
      " - 0s - loss: 0.6644 - acc: 0.5904\n",
      "Epoch 43/200\n",
      " - 0s - loss: 0.6643 - acc: 0.5927\n",
      "Epoch 44/200\n",
      " - 0s - loss: 0.6643 - acc: 0.5878\n",
      "Epoch 45/200\n",
      " - 0s - loss: 0.6639 - acc: 0.5872\n",
      "Epoch 46/200\n",
      " - 0s - loss: 0.6641 - acc: 0.5904\n",
      "Epoch 47/200\n",
      " - 0s - loss: 0.6642 - acc: 0.5891\n",
      "Epoch 48/200\n",
      " - 0s - loss: 0.6630 - acc: 0.5891\n",
      "Epoch 49/200\n",
      " - 0s - loss: 0.6633 - acc: 0.5904\n",
      "Epoch 50/200\n",
      " - 0s - loss: 0.6633 - acc: 0.5865\n",
      "Epoch 51/200\n",
      " - 0s - loss: 0.6634 - acc: 0.5901\n",
      "Epoch 52/200\n",
      " - 0s - loss: 0.6625 - acc: 0.5888\n",
      "Epoch 53/200\n",
      " - 0s - loss: 0.6626 - acc: 0.5891\n",
      "Epoch 54/200\n",
      " - 0s - loss: 0.6626 - acc: 0.5927\n",
      "Epoch 55/200\n",
      " - 0s - loss: 0.6622 - acc: 0.5882\n",
      "Epoch 56/200\n",
      " - 0s - loss: 0.6618 - acc: 0.5904\n",
      "Epoch 57/200\n",
      " - 0s - loss: 0.6621 - acc: 0.5946\n",
      "Epoch 58/200\n",
      " - 0s - loss: 0.6621 - acc: 0.5953\n",
      "Epoch 59/200\n",
      " - 0s - loss: 0.6616 - acc: 0.5911\n",
      "Epoch 60/200\n",
      " - 0s - loss: 0.6618 - acc: 0.5895\n",
      "Epoch 61/200\n",
      " - 0s - loss: 0.6616 - acc: 0.5872\n",
      "Epoch 62/200\n",
      " - 0s - loss: 0.6614 - acc: 0.5927\n",
      "Epoch 63/200\n",
      " - 0s - loss: 0.6611 - acc: 0.5972\n",
      "Epoch 64/200\n",
      " - 0s - loss: 0.6614 - acc: 0.5985\n",
      "Epoch 65/200\n",
      " - 0s - loss: 0.6613 - acc: 0.5891\n",
      "Epoch 66/200\n",
      " - 0s - loss: 0.6609 - acc: 0.5907\n",
      "Epoch 67/200\n",
      " - 0s - loss: 0.6615 - acc: 0.5901\n",
      "Epoch 68/200\n",
      " - 0s - loss: 0.6609 - acc: 0.5982\n",
      "Epoch 69/200\n",
      " - 0s - loss: 0.6605 - acc: 0.5888\n",
      "Epoch 70/200\n",
      " - 0s - loss: 0.6602 - acc: 0.5943\n",
      "Epoch 71/200\n",
      " - 0s - loss: 0.6607 - acc: 0.5946\n",
      "Epoch 72/200\n",
      " - 0s - loss: 0.6606 - acc: 0.5904\n",
      "Epoch 73/200\n",
      " - 0s - loss: 0.6605 - acc: 0.5927\n",
      "Epoch 74/200\n",
      " - 0s - loss: 0.6605 - acc: 0.5962\n",
      "Epoch 75/200\n",
      " - 0s - loss: 0.6603 - acc: 0.5943\n",
      "Epoch 76/200\n",
      " - 0s - loss: 0.6603 - acc: 0.5891\n",
      "Epoch 77/200\n",
      " - 0s - loss: 0.6599 - acc: 0.5937\n",
      "Epoch 78/200\n",
      " - 0s - loss: 0.6599 - acc: 0.5946\n",
      "Epoch 79/200\n",
      " - 0s - loss: 0.6599 - acc: 0.5998\n",
      "Epoch 80/200\n",
      " - 0s - loss: 0.6601 - acc: 0.5907\n",
      "Epoch 81/200\n",
      " - 0s - loss: 0.6597 - acc: 0.5930\n",
      "Epoch 82/200\n",
      " - 0s - loss: 0.6594 - acc: 0.5917\n",
      "Epoch 83/200\n",
      " - 0s - loss: 0.6594 - acc: 0.5940\n",
      "Epoch 84/200\n",
      " - 0s - loss: 0.6591 - acc: 0.5930\n",
      "Epoch 85/200\n",
      " - 0s - loss: 0.6592 - acc: 0.5946\n",
      "Epoch 86/200\n",
      " - 0s - loss: 0.6593 - acc: 0.5959\n",
      "Epoch 87/200\n",
      " - 0s - loss: 0.6590 - acc: 0.5907\n",
      "Epoch 88/200\n",
      " - 0s - loss: 0.6587 - acc: 0.5966\n",
      "Epoch 89/200\n",
      " - 0s - loss: 0.6582 - acc: 0.5933\n",
      "Epoch 90/200\n",
      " - 0s - loss: 0.6588 - acc: 0.6005\n",
      "Epoch 91/200\n",
      " - 0s - loss: 0.6587 - acc: 0.5924\n",
      "Epoch 92/200\n",
      " - 0s - loss: 0.6582 - acc: 0.5975\n",
      "Epoch 93/200\n",
      " - 0s - loss: 0.6580 - acc: 0.5992\n",
      "Epoch 94/200\n",
      " - 0s - loss: 0.6586 - acc: 0.5975\n",
      "Epoch 95/200\n",
      " - 0s - loss: 0.6587 - acc: 0.5930\n",
      "Epoch 96/200\n",
      " - 0s - loss: 0.6579 - acc: 0.5995\n",
      "Epoch 97/200\n",
      " - 0s - loss: 0.6579 - acc: 0.5966\n",
      "Epoch 98/200\n",
      " - 0s - loss: 0.6583 - acc: 0.5988\n",
      "Epoch 99/200\n",
      " - 0s - loss: 0.6576 - acc: 0.5959\n",
      "Epoch 100/200\n",
      " - 0s - loss: 0.6588 - acc: 0.5985\n",
      "Epoch 101/200\n",
      " - 0s - loss: 0.6581 - acc: 0.5933\n",
      "Epoch 102/200\n",
      " - 0s - loss: 0.6582 - acc: 0.5950\n",
      "Epoch 103/200\n",
      " - 0s - loss: 0.6581 - acc: 0.5911\n",
      "Epoch 104/200\n",
      " - 0s - loss: 0.6576 - acc: 0.6005\n",
      "Epoch 105/200\n",
      " - 0s - loss: 0.6581 - acc: 0.5956\n",
      "Epoch 106/200\n",
      " - 0s - loss: 0.6573 - acc: 0.5933\n",
      "Epoch 107/200\n",
      " - 0s - loss: 0.6574 - acc: 0.5972\n",
      "Epoch 108/200\n",
      " - 0s - loss: 0.6567 - acc: 0.5969\n",
      "Epoch 109/200\n",
      " - 0s - loss: 0.6575 - acc: 0.5933\n",
      "Epoch 110/200\n",
      " - 0s - loss: 0.6581 - acc: 0.5930\n",
      "Epoch 111/200\n",
      " - 0s - loss: 0.6572 - acc: 0.5943\n",
      "Epoch 112/200\n",
      " - 0s - loss: 0.6574 - acc: 0.5872\n",
      "Epoch 113/200\n",
      " - 0s - loss: 0.6572 - acc: 0.6021\n",
      "Epoch 114/200\n",
      " - 0s - loss: 0.6580 - acc: 0.5956\n",
      "Epoch 115/200\n",
      " - 0s - loss: 0.6568 - acc: 0.5985\n",
      "Epoch 116/200\n",
      " - 0s - loss: 0.6571 - acc: 0.5969\n",
      "Epoch 117/200\n",
      " - 0s - loss: 0.6568 - acc: 0.5940\n",
      "Epoch 118/200\n",
      " - 0s - loss: 0.6569 - acc: 0.5962\n",
      "Epoch 119/200\n",
      " - 0s - loss: 0.6572 - acc: 0.5930\n",
      "Epoch 120/200\n",
      " - 0s - loss: 0.6572 - acc: 0.5927\n",
      "Epoch 121/200\n",
      " - 0s - loss: 0.6569 - acc: 0.6008\n",
      "Epoch 122/200\n",
      " - 0s - loss: 0.6564 - acc: 0.6005\n",
      "Epoch 123/200\n",
      " - 0s - loss: 0.6564 - acc: 0.5946\n",
      "Epoch 124/200\n",
      " - 0s - loss: 0.6563 - acc: 0.6008\n",
      "Epoch 125/200\n",
      " - 0s - loss: 0.6568 - acc: 0.6005\n",
      "Epoch 126/200\n",
      " - 0s - loss: 0.6566 - acc: 0.5962\n",
      "Epoch 127/200\n",
      " - 0s - loss: 0.6566 - acc: 0.6027\n",
      "Epoch 128/200\n",
      " - 0s - loss: 0.6557 - acc: 0.5975\n",
      "Epoch 129/200\n",
      " - 0s - loss: 0.6561 - acc: 0.5975\n",
      "Epoch 130/200\n",
      " - 0s - loss: 0.6566 - acc: 0.5995\n",
      "Epoch 131/200\n",
      " - 0s - loss: 0.6561 - acc: 0.5940\n",
      "Epoch 132/200\n",
      " - 0s - loss: 0.6562 - acc: 0.5943\n",
      "Epoch 133/200\n",
      " - 0s - loss: 0.6564 - acc: 0.6030\n",
      "Epoch 134/200\n",
      " - 0s - loss: 0.6562 - acc: 0.6008\n",
      "Epoch 135/200\n",
      " - 0s - loss: 0.6555 - acc: 0.5943\n",
      "Epoch 136/200\n",
      " - 0s - loss: 0.6553 - acc: 0.6040\n",
      "Epoch 137/200\n",
      " - 0s - loss: 0.6555 - acc: 0.5969\n",
      "Epoch 138/200\n",
      " - 0s - loss: 0.6559 - acc: 0.5943\n",
      "Epoch 139/200\n",
      " - 0s - loss: 0.6549 - acc: 0.6047\n",
      "Epoch 140/200\n",
      " - 0s - loss: 0.6559 - acc: 0.6030\n",
      "Epoch 141/200\n",
      " - 0s - loss: 0.6558 - acc: 0.6050\n",
      "Epoch 142/200\n",
      " - 0s - loss: 0.6554 - acc: 0.5998\n",
      "Epoch 143/200\n",
      " - 0s - loss: 0.6550 - acc: 0.5975\n",
      "Epoch 144/200\n",
      " - 0s - loss: 0.6549 - acc: 0.5995\n",
      "Epoch 145/200\n",
      " - 0s - loss: 0.6550 - acc: 0.5979\n",
      "Epoch 146/200\n",
      " - 0s - loss: 0.6551 - acc: 0.6008\n",
      "Epoch 147/200\n",
      " - 0s - loss: 0.6551 - acc: 0.5946\n",
      "Epoch 148/200\n",
      " - 0s - loss: 0.6552 - acc: 0.6040\n",
      "Epoch 149/200\n",
      " - 0s - loss: 0.6548 - acc: 0.5969\n",
      "Epoch 150/200\n",
      " - 0s - loss: 0.6552 - acc: 0.5985\n",
      "Epoch 151/200\n",
      " - 0s - loss: 0.6551 - acc: 0.6008\n",
      "Epoch 152/200\n",
      " - 0s - loss: 0.6548 - acc: 0.6034\n",
      "Epoch 153/200\n",
      " - 0s - loss: 0.6548 - acc: 0.6017\n",
      "Epoch 154/200\n",
      " - 0s - loss: 0.6549 - acc: 0.5966\n",
      "Epoch 155/200\n",
      " - 0s - loss: 0.6550 - acc: 0.6034\n",
      "Epoch 156/200\n",
      " - 0s - loss: 0.6537 - acc: 0.6050\n",
      "Epoch 157/200\n",
      " - 0s - loss: 0.6546 - acc: 0.6069\n",
      "Epoch 158/200\n",
      " - 0s - loss: 0.6549 - acc: 0.6043\n",
      "Epoch 159/200\n",
      " - 0s - loss: 0.6548 - acc: 0.5975\n",
      "Epoch 160/200\n",
      " - 0s - loss: 0.6541 - acc: 0.6043\n",
      "Epoch 161/200\n",
      " - 0s - loss: 0.6543 - acc: 0.6014\n",
      "Epoch 162/200\n",
      " - 0s - loss: 0.6544 - acc: 0.5992\n",
      "Epoch 163/200\n",
      " - 0s - loss: 0.6534 - acc: 0.6082\n",
      "Epoch 164/200\n",
      " - 0s - loss: 0.6542 - acc: 0.5998\n",
      "Epoch 165/200\n",
      " - 0s - loss: 0.6541 - acc: 0.6053\n",
      "Epoch 166/200\n",
      " - 0s - loss: 0.6545 - acc: 0.6034\n",
      "Epoch 167/200\n",
      " - 0s - loss: 0.6540 - acc: 0.6005\n",
      "Epoch 168/200\n",
      " - 0s - loss: 0.6533 - acc: 0.6021\n",
      "Epoch 169/200\n",
      " - 0s - loss: 0.6532 - acc: 0.6050\n",
      "Epoch 170/200\n",
      " - 0s - loss: 0.6539 - acc: 0.6043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      " - 0s - loss: 0.6539 - acc: 0.5998\n",
      "Epoch 172/200\n",
      " - 0s - loss: 0.6545 - acc: 0.6043\n",
      "Epoch 173/200\n",
      " - 0s - loss: 0.6532 - acc: 0.6053\n",
      "Epoch 174/200\n",
      " - 0s - loss: 0.6542 - acc: 0.5992\n",
      "Epoch 175/200\n",
      " - 0s - loss: 0.6539 - acc: 0.6063\n",
      "Epoch 176/200\n",
      " - 0s - loss: 0.6536 - acc: 0.6021\n",
      "Epoch 177/200\n",
      " - 0s - loss: 0.6524 - acc: 0.6060\n",
      "Epoch 178/200\n",
      " - 0s - loss: 0.6538 - acc: 0.6050\n",
      "Epoch 179/200\n",
      " - 0s - loss: 0.6540 - acc: 0.5969\n",
      "Epoch 180/200\n",
      " - 0s - loss: 0.6526 - acc: 0.6005\n",
      "Epoch 181/200\n",
      " - 0s - loss: 0.6528 - acc: 0.6001\n",
      "Epoch 182/200\n",
      " - 0s - loss: 0.6535 - acc: 0.6069\n",
      "Epoch 183/200\n",
      " - 0s - loss: 0.6531 - acc: 0.6050\n",
      "Epoch 184/200\n",
      " - 0s - loss: 0.6529 - acc: 0.6014\n",
      "Epoch 185/200\n",
      " - 0s - loss: 0.6534 - acc: 0.5975\n",
      "Epoch 186/200\n",
      " - 0s - loss: 0.6531 - acc: 0.6017\n",
      "Epoch 187/200\n",
      " - 0s - loss: 0.6534 - acc: 0.6102\n",
      "Epoch 188/200\n",
      " - 0s - loss: 0.6526 - acc: 0.6014\n",
      "Epoch 189/200\n",
      " - 0s - loss: 0.6523 - acc: 0.6027\n",
      "Epoch 190/200\n",
      " - 0s - loss: 0.6530 - acc: 0.6050\n",
      "Epoch 191/200\n",
      " - 0s - loss: 0.6533 - acc: 0.6021\n",
      "Epoch 192/200\n",
      " - 0s - loss: 0.6535 - acc: 0.6034\n",
      "Epoch 193/200\n",
      " - 0s - loss: 0.6524 - acc: 0.6014\n",
      "Epoch 194/200\n",
      " - 0s - loss: 0.6520 - acc: 0.6017\n",
      "Epoch 195/200\n",
      " - 0s - loss: 0.6521 - acc: 0.6040\n",
      "Epoch 196/200\n",
      " - 0s - loss: 0.6521 - acc: 0.6053\n",
      "Epoch 197/200\n",
      " - 0s - loss: 0.6532 - acc: 0.6056\n",
      "Epoch 198/200\n",
      " - 0s - loss: 0.6526 - acc: 0.6063\n",
      "Epoch 199/200\n",
      " - 0s - loss: 0.6528 - acc: 0.6011\n",
      "Epoch 200/200\n",
      " - 0s - loss: 0.6521 - acc: 0.6005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3485e860>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the training data to fit (train) the model\n",
    "modelNN.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 0s - loss: 0.6844 - acc: 0.5623\n",
      "Loss: 0.6843674414323799, Accuracy: 0.5622710585594177\n"
     ]
    }
   ],
   "source": [
    "# evaluate model by using test data\n",
    "model_loss, model_accuracy = modelNN.evaluate(\n",
    "    X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate ROC Curve vs Precision Recall Curve\n",
    "\n",
    "##### Generally, the use of ROC curves and precision-recall curves are as follows:\n",
    "#### ROC curves should be used when there are roughly equal numbers of observations for each class.\n",
    "#### Precision-Recall curves should be used when there is a moderate to large class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "probs = modelNN.predict_proba(X_test_scaled)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.586\n"
     ]
    }
   ],
   "source": [
    "# calculate AUC\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "print('AUC: %.3f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8lFW+x/HPmQmh94ROCL0IIhBBQREFlaasrr2B7q533fWuZS1Y17LFq2vbu167Bt1Vd0VUBOxljSiEoNIiKEJgQu8gEEgy5/7xJGQyTJKBPFPzfb9eeTHzzJOZ85jw9XCec37HWGsREZHk4ol1A0RExH0KdxGRJKRwFxFJQgp3EZEkpHAXEUlCCncRkSSkcBcRSUIKdxGRJKRwFxFJQimx+uC0tDSbmZkZq48XEUlICxcu3GqtTa/pvJiFe2ZmJnl5ebH6eBGRhGSMWRPOeRqWERFJQgp3EZEkpHAXEUlCCncRkSSkcBcRSUI1hrsx5gVjzGZjzNIqXjfGmL8ZY1YaYxYbYwa730wRETkS4UyFzAb+DrxUxevjgJ5lX8OAJ8v+FBERAF8uFORA5snO8/LHnYdG7CNrDHdr7efGmMxqTpkEvGSd/frmGWNaGGPaW2s3uNRGEZHElZcNs28EW4rFA8ZgsOCtD5NnRizg3Rhz7wj4Ap4Xlh07jDHmamNMnjEmb8uWLS58tIhIHJv3JMy6Dmxp2QG/89j6ofSg04OPEDfC3YQ4FnLXbWvtM9baLGttVnp6jatnRUQSV142vDf18OPG63x5UyuGaSLAjfIDhUDngOedgPUuvK+ISPwLHE8vH2IpmAuzrsNS0ft1erwezIRHYP+22I+5h2EmcK0x5jWcG6m7NN4uInXC2vmQPQH8JeDxwpAp0CKDkkWvk0LlYDcYmPgoZE2JStNqDHdjzKvAKCDNGFMI/AGoB2CtfQqYA4wHVgL7gCsj1VgRkbiyYg74i53H/hJY8BzgBGtgr90J9seiFuzlbaiWtfbiGl63wG9da5GISCLw5cLqihuiFvhHy9/y5w1DOK/dJu7d/QeM/6Azvj7hkagGO8Sw5K+ISFwKnpM+9zHYVQj9z4eBF8H6r2HZm7Dkdae3XqbUGrZs28bNEwczeXgmnnVZUZnPXhXjdLyjLysry6qeu4jEDV8ufPsKfP2SM13ReMFawF/jt1oMB00qO8+bTttjRka0mcaYhdbarJrOU89dRMSXC9MmQsmBimOH5qYHaJQG+7YBtvKYesfBpJ75F9pmxM/ifBUOE5G6yZcLOQ9XDMOUHAxxUtAynkGX4ffWpwQDFvwYrDcVxj6AiaNgB/XcRaSuWDsfVn0KGcOd1aGvnO+sFDUGmmVQee2lAW89GPcQrPwA9mykeOCl/G3nScwraskp9VcwcmBvBrQsxXSNzZh6TRTuIpKcgm+MvjjWCfNg1sK+wHIoBrqfCqNuc0K7bJbLqo17eOrtHM4aOIpLJ/yGlo1TI34JtaFwF5HkUR7om5c7s1mwYDzQOL1ysDdKg31bK553PxVWfuL06L2ph4J974ESPszfxM8GdaR3u6Z8fOMoMlo3ivplHQ2Fu4gkB18uZE+E0gOVj1s/7N9R+VjGMPjhQygtdoZfRlzvfAVMXcz5YQu3zVjCup376d+xGT3aNE2YYAeFu4gki4Kcw4O9XM/TawxzADoPZde+Yv40fRH/ziukW1pj/nX1ifRo0zR61+EShbuIJIei3aGPG2+1YR6o1G/5+VNfsnrrXn4zqju/G92TBvW8EW54ZCjcRSQx5WXDNy9BgxbQpA0seq3y643SIOMEGHFdlWFebvveg7RoWA+vx3Dzmb3p2KIh/Ts2j2z7I0zhLiKJxZcLH/0B1nxZ/Xn9znKKdVXDWsuMr9dx36x8bh3bh0uGZXDmMe1cbGzsKNxFJL4FTmksOQDTziZkSQDjrVhV6qkHAy+p9m0Ld+zj9jeX8vn3WxjSpSVDu7Zyv+0xpHAXkfiVlw2zrqeKzd0qeOrB+L/Cxm8BAwMvrnZh0ZvfFHLnm0uxwL1nH8PlJ3TB4wm1qVziUriLSHzKy3b2Hw3UoCUUBU1r7DIcxtx7RKtEWzWuz5DMVvz5nP50apk40xuPhMJdROKHLxdyHoUN38KeELt1Zg4vm9J4ZHXSi0v9PJuzipJSy+9G9+SUXumM7JmGMcnVWw+kcBeR2CofU2/YGmbdQNUldj1VT2msxtJ1u7j1jcUsW7+bswZ2wFqLMSapgx0U7iISC+WBjgc+vpcax9TL9x+tYUpjoKLiUv728Q88/fkqWjZK5anLBjO2f/vatjxhKNxFJLoOlQkoL7FbQ7Af5TZ1a7bt49mcVZw7qCN3TuhH80b1jqq5iUrhLiKRV95T37UOvn+v6jIBeHCGZQwMOB/a9Dmiber2Hijh/WUbOXdwJ3q3a8onvx9F51bJecO0Jgp3EYksXy5MOwtKikK/brxOca/y+un7tx3VvqP/+X4Lt89Ywvpd+zm2U3N6tGlaZ4MdFO4iEmlV7nIE4IEhV0Dzzke9kfSOvQe5f3Y+M75eR/f0xrz+X4lZ6MttCncRiYzAWTAeL/iDZ8F4IKW+s5L0KHcyKi/0tWbbPq49tQfXntYjYQt9uU3hLiLuCQz02TeG2GTaAx0HOb30Bs2Oure+7acDtGyUitdjmDq2Dx1bNuSYDold6MttCncRcUdedkCgG0LOgjEG+kyAk39/VB9hreX1hYX8cVY+t47rw6XDunBGkhT6cpvCXUTCE1jAK7i3/cFd8OXfAg4EBbspGyrxplbsaXqkH799H7e/uYScH7YyNLMVJ3ZrfVTvU1co3EWkZr5cyJ7g7GTkSYGsK6FFRtlrC+C7t0N8kwewtZ4FAzDj60LufGspBrj/Z/25dGhG0hX6cpvCXUQqBPfO87Jh6XTnxmf5oiN/MeQ+U8MbeZwVpbUI9EBpTeoztGsr/nTOADq2aFir96orFO4i4gjunXcZAas/C33u2P+BQZc6j7/5J7x3a8CLZaUCjnBFaaDiUj9P/+dHSv1w3ZiejOyVzshe6Uf9fnWRwl1EHCverdw7ryrY8UDxXqhfNpf8hF9DSgNny7um7Stva3cUlq7bxc3TF/Pdht1MOq6i0JccmbDC3RgzFngc8ALPWWsfCHo9A5gGtCg7Z6q1do7LbRWRSOowuOyBcYZhBk+B3KcqXvfUK1tJGuKmaNaUWvXUwSn09dhHP/BszipaNU7l6cuHJM2Wd7FQY7gbY7zAE8DpQCGwwBgz01qbH3DancC/rbVPGmP6AXOAzAi0V0Tc5suFuY/BjgLneXpvGHaNE9Zt+jo3S/tOgrb9jqjU7pFau30fz3+xivMGd+L28X3rXKEvt4XTcx8KrLTWrgIwxrwGTAICw90CzcoeNwdCVNkXkbjjy4UXx4G/pOLYluXw3lQnzIN75C6H+p6iYt5bupHzszrTq21TPr1pVNLujBRt4YR7R8AX8LwQGBZ0zj3AB8aY/wYaA2NcaZ2IRI4v1wnxwGAvV3rQ6aVHoIde7tPlm7njzSVs3F3EoIwW9GjTVMHuIk8Y54S6kxG89OxiINta2wkYD7xsjDnsvY0xVxtj8owxeVu2bDny1oqIO3y58OJ4WLcwxIueWi02qsn2vQe54V/fcmX2AhrXT2H6NcNV6CsCwum5FwKdA5534vBhl18AYwGstV8ZYxoAacDmwJOstc8AzwBkZWXVtPWKiLjNlwurc2CXz5kRE6zLcOgxJmLj6qV+y3lPfsna7fv43eie/PbU7tRPUaGvSAgn3BcAPY0xXYF1wEXAJUHnrAVGA9nGmL5AA0Bdc5F4cmgHpCo2yvDWhzH3RiTUt+w5QOvGTqGv28f3pWPLhvRt36zmb5SjVuOwjLW2BLgWeB/4DmdWzDJjzH3GmLPLTvs98CtjzCLgVWCKtVY9c5F4MvfxqoO94xCYMsv1YLfW8q8Faznt4c94JXctAGP6tVWwR0FY89zL5qzPCTp2d8DjfGCEu00TEdfkZcPyWZWPBc5bH/uA68G+dts+ps5YzJc/bmNY11ac1CPN1feX6mmFqkiyCVW9cf6Th583+LJa7YBUnekLC7nrraV4PYY/ndOfi49Xoa9oU7iLJJND+5UeBG8KjL4Hdq515q4H8qTUagekmrRtVp/h3Vvzx3P60765Cn3FgsJdJJkserViI+rSg/DB7aHPG3y5q8F+sMTPk5/9iN9abji9Fyf3TOfknir0FUsKd5Fk4MuFRa9A3rTKx0fc4Pw599GKY556Tq/dJYt8O7ll+mJWbNrDuYM6qtBXnFC4iyQyXy58+wp8Pc25ORqsQVNnS7uWma5VbSy3/2Apj3y4gue/WE2bpg147oosxvRrW+v3FXco3EUSTfkN043LYNkMQu5VCs7WduWrTF2o2nhYM3bsY9qXa7hoaAZTx/WhWQMV+oonCneRRJKXDbNvCN1LD2S8MOER12+Y7i4r9HVBWaGvz24eRQftjBSXFO4i8a7gC1j2pjPDZf5T1Z/rSYHBV8DAi10P9k+Wb+L2GUvZvKeIwRkt6dGmiYI9jincReJV+U3ShVWMp1ficYZdIhDq2346wH2z8nn72/X0btuUpy4fQo82TVz9DHGfwl0kHgQvPHrnelj4Ys3fl9Yb0nq6dpM0WKnfcv5TX+HbsY8bxvTimlHdSU0Jp5isxJrCXSTWAsfRjRda94CtK6o42QP4K8bUXb5JWm7zniLSGtfH6zHcMaEvnVo2onc7leVNJAp3kUgJ7o2HKguwdj7Muq7ie2xp1cHuTYVxD8H+bREryev3W15dsJa/zFnOreP6cPkJXRjdV9MbE5HCXcRN5QHesDW8exOUFju97J5nwMoPwV8KHi8cdyk07wTLQ+wj32U4rPky4EDkxtMDFWzdy9QZi5m3ajvDu7fmFK0wTWgKd5HaKg90Typ8eBeHzTu3pfD9uxXP/SXOoqOQPE5N9U35ri86qs6/83zc9dZSUr0eHjh3ABce31mrTBOcwl2kNvKyYfaNToBXp/cE+PETp96LNxUuf7NiqOals53jgXPTOw+N2Hh6KB1bNGRkr3Tun9Sfds0bRO1zJXJMrPbUyMrKsnl5eTH5bJFaKe+pb1gK+TOqOdEDWPDWgymznUPBY+6B7xehcfRQDpSU8n+f/oi1lhvP6B2VzxR3GGMWWmuzajpPPXeRcJXPO//6H6H3HwUqBXqom5+hwru8px4l36zdwa1vLOb7TT/x88GdVOgrSSncRcLhy4Xs8c4N0ip5YOKjEZ3NUhv7Dpbw8Aff88Lc1bRr1oAXpmRxWh/NhElWCneRcBTk1BDsxgn2KI6TH6l1O/bz8rw1XDosg1vH9qGpCn0lNYW7SDgatgYMFTNhDBiPs+AogitEa2vX/mLeXbKBi4Zm0LNtU/5z8yjtjFRHKNxFauLLhTk3cSjYjReGTI74vPPa+mDZRu58aynb9h4kK7MVPdo0UbDXIQp3kZoserXyDVTrdxYgxWmwb/3pAPfMXMasxRvo064pz03OUqGvOkjhLlIdXy4szK58zJNSsQlGnCn1W8578kvW7yzipjN68V+ndKeeV4W+6iKFu0h1fvzk8HK7gy+Lu177pt1FpDdxCn394axj6NSyIT3bqtBXXab/pYtUp9PxlZ9767u6uXRt+f2Wl+etYfTD/+Gf89cAcGqfNgp2Uc9d5DCBK0Y7DnGONesEHY6Lq1kxq7b8xNQZS8hdvZ2TeqQxqnebWDdJ4ojCXaRc8ApUTwoce6Hz2u51sG+bE+5x4F8L1nL328uon+LhwfOO5fwhnbTKVCpRuIuAU1f9xXGVC4D5S+Dbf5Y9sU5xr4KcuOi5d2rZiFG9nUJfbZqp0JccTuEuAs6MmFCVHbucDOtyobTEqeYYo1kyB0pK+d+PVwJw05m9GdEjjRE90mLSFkkMCneRqnhTYczdzuMoV20MtHDNdm6Zvpgft+zlgiwV+pLwKNxFfLmwd0vlY30mVr55GoNQ33ughIfeX8G0rwro0Lwh064ayim9tDuShCesqZDGmLHGmBXGmJXGmKlVnHOBMSbfGLPMGPOKu80UiRBfLkw7y9kCL1CTNjEfW1+/cz+v5K7lihO68P4NIxXsckRq7LkbY7zAE8DpQCGwwBgz01qbH3BOT+A2YIS1docxRnOyJDEU5EDJwRAvxGYTm137ipm9ZAOXDHMKfeXcciptdcNUjkI4wzJDgZXW2lUAxpjXgElAfsA5vwKesNbuALDWbna7oSIRkXkyeFOcmTAAGGejjRgsVHpv6Ubuensp2/ceZFi3VnRPb6Jgl6MWTrh3BHwBzwuBYUHn9AIwxswFvMA91tr3gt/IGHM1cDVARkbG0bRXxF3+UmjVA7bkw4ALoU3vqN843byniHtmLmPOko30a9+MF6ccT/d0FfqS2gkn3EPdlg/+N2sK0BMYBXQCcowx/a21Oyt9k7XPAM+As4fqEbdWxE152TDreg79OufPgKFzohrspX7LBU99xfpdRdx8Zm+uHtlNhb7EFeGEeyHQOeB5J2B9iHPmWWuLgdXGmBU4Yb/AlVaKuG3u3+HDOyofKy2J2iKlDbv207ZpA6fQ19nH0LllI5XlFVeF00VYAPQ0xnQ1xqQCFwEzg855CzgVwBiThjNMs8rNhoq4Ji/78GAHZ2elCC9S8vst2XNXM/rh//CP8kJfvdso2MV1NfbcrbUlxphrgfdxxtNfsNYuM8bcB+RZa2eWvXaGMSYfKAVuttZui2TDRY5IeTGw+s1hzu9DnGBgwiMR7bWv3PwTU99YTN6aHYzslc5pfTSpTCLHWBuboe+srCybl5cXk8+WOqZ8LnvJgbIDwb/zBiY+FtHNrV/LXcvdM5fRsJ6Xuyf249zBHbXKVI6KMWahtTarpvO0QlWSQ3nPvGFr2L+tYnilIAd2FUJJURXfGPlgB8ho3Ygxfdtw79n9SW9aP6KfJQIKd0kGedkw+4aAHZOMM34OZceCesjG6xQJM15nKCYCwV5UXMrfPv4BgFvG9mF49zSGd1ehL4kehbskpkNj6M1gzk1BL9qgCo+BwzAeGHIFNO8csfnseQXbueWNxazaspeLju+sQl8SEwp3SSyHNtR42am3HnIZRtkqU3AWKXm8FY+9qc7q0wiE+k8HSnjoveW8NG8NHVs05KWrhjJS9WAkRhTukjjmPQnv3UblnniIm6NZV8LAi52n5aV6Ax9HaEbMxl37eW2Bj8knZnLzmb1pXF9/vSR2NFtGEsMPH8E/f17Fix7AH9Ex9Krs2HuQWUs2cPkJXQDYvLtIOyNJRGm2jCQHXy7MfQx8VSx29qbCuIcqZshEqXSAtZZ3l27k7reXsnNfMcO7t6Z7ehMFu8QNhbvEr+DaL5V4nB76wIujXnd98+4i7np7Ke8v28SAjs156aphKvQlcUfhLvFpwfMw+8YqXjSQNRkmPhrVJoFT6Ov8p79i464ibhvXh1+c1JUUFfqSOKRwl/jjy60m2D2QUj/q9dbX79xPu2ZOoa/7JvWnc8uGdFNvXeKYwl3iT0FO6OMDLoA2faI6tl7qt7z0VQEPvreC28b34YoTM7XdnSQEhbvEj8ASAoGMByY8GtVZMAArN+/hlumL+XrtTkb1Tmd037ZR/XyR2lC4S+z5cuGjP8Car3BungYsTIrB9EaAV+av5Z6Zy2hc38ujFw7kZ8ep0JckFoW7xJYvF14c66wePSRodsz+6FePzkxrxBnHtOWes48hrYkKfUniUbhLdJUPvWSeDJvy4cvHg4K9jCkrGeBNjfgGGuAU+nr0o+8xGKaOU6EvSXwKd4mevGxnFowt5dCq0lDKh2KitDBp/qptTJ2xhNVb93LpsAwV+pKkoHCX6PDlBpXlrSLY03vD2X+PymyYPUXF/M97y/nHvLVktGrEK78cxvAe6q1LclC4S3QsejUg2EMpm78epWAH2LT7ANMXFvLLk7py4xm9aJSqvw6SPPTbLJHny3WGZAIZLwz/b9i4GNodCw2aRWUIZvveg8xevJ7LT8ykR5sm5NxymnZGkqSkcJfIW/Qqhw3DDLkCTr83ak2w1jJr8QbumbmM3UXFjOiRRrf0Jgp2SVoKd4msNV8e3mv31Itq+YBNu4u4482lfPTdJo7t1Jx/njdMpQMk6SncJbKWvcVhvfbBl0W1fMAFZYW+7hjflytHZKrQl9QJCneJrA6DKj/3RqfoV+GOfbRv3hCvx3D/pP5ktGpEZlrjiH+uSLxQF0Yiq11/589up0HWVTBlVkR77aV+y3M5qxjzyH/4x7w1AIzsla5glzpHPXeJjuOvgr5nRfQjVmzcwy1vLGaRbyej+7ThjGNU6EvqLoW7uM+XCzmPws4C6FS21WP+TGjSNmK99n/MW8O97yyjaYN6PH7RcZw9sINWmUqdpnAXd+Vlw6zrKp5vznf+XDIdvnsHJs90NeDLSwX0aNOE8QPac/fEfrRWoS8Rhbu4KDjYK/FD6UGnaJgL4b7/YCmPfLgCj8dw27i+nNCtNSd0a13zN4rUEQp3qZ3yKo8NWsDs34c+x1PPKT3gUoXHr37cxtQZi1mzbR+Xn9BFhb5EQlC4y5EL3DFpzu/BX1L1uSOuhz4TKsr81qLXvruomL/MWc6ruWvp0roRr/xqmMryilQhrHA3xowFHge8wHPW2geqOO884HXgeGttnmutlPix5iuYdlZAoNsqTjQw8bGKHZRcGIrZvPsAb32zjqtHduOGMb1omOqt9XuKJKsaw90Y4wWeAE4HCoEFxpiZ1tr8oPOaAr8D5keioRInlr4B/uIqXiyr0e7i1njbfjrAO4vWM2VEV3q0acIXt56qG6YiYQin5z4UWGmtXQVgjHkNmATkB513P/AgcJOrLZT40m6A86fxgCfFGUv3l4K3Hox7yLUNNqy1zFy0nntmLuOnAyWM7JVOt/QmCnaRMIUT7h0BX8DzQmBY4AnGmEFAZ2vtLGOMwj1ZrZ0PvrJ/mLUd4Kw4bdvPlfH0QOt37ufOt5byyfLNHNe5BQ+ed6wKfYkcoXDCPdQ0hEMDrcYYD/AoMKXGNzLmauBqgIyMjPBaKLHly4VFr8CWlbDmCw796DcuhvemOvPWT65ilsxRKCn1c9Ez89iy5wB3TezHlOGZeD2aCSNypMIJ90Kgc8DzTsD6gOdNgf7AZ2XT0doBM40xZwffVLXWPgM8A5CVlVXVnTiJlfJZMEW7Yf3XkN4Pcp8m9E1T6+q8dd/2fXRo0ZAUr4c/nzOAjFaNyGjdqNbvK1JXhRPuC4CexpiuwDrgIuBQWT9r7S7g0Hw0Y8xnwE2aLZNgfLmQPRFKD1QcW/151ecbjyvz1ktK/bwwdzUPf/A9t43rw5QRXTmpp6Y3itRWjeFurS0xxlwLvI8zFfIFa+0yY8x9QJ61dmakGylRsOjVysEekseZAdNuoCs3Tr/bsJtb31jM4sJdnN6vLeMGtD/q9xKRysKa526tnQPMCTp2dxXnjqp9sySiyodfysM51B6n5YwXbKmr0xsBXv6qgHvfyad5w3r8/ZJBTBjQXqtMRVykFap1jS8XXhzvzFU3Hug0FHau5bDdklp1g+HXuT4bprxUQK+2TTlrYAfumtiPVo1Ta/2+IlKZwr2uKcipWIRk/bCj4PDhGOOFc56uCHMXQn3fwRL++v73pHgNt4/vy7BurRmmQl8iEaNwrwsCh2ECb4B668OFLzuPsyc4s1/Kh19cLMs7d+VWps5YjG/7fqYMz1ShL5EoULgnu7xsmH2D00s/TNkUx85DYcps1xcj7dpfzJ9nf8e/8nx0TWvMv//rRIZ2beXKe4tI9RTuySZwrnpBDqxbWPn1pu1hz0bAOmUDyuepl3+5aOtPB3hn8Xp+fUp3rh/Tkwb1VOhLJFoU7skgsATvu7dUP6Wx42BY+YkzBONSffVAW/Y4hb6uOqkr3dOb8MWtp+mGqUgMKNwTXbXDLsE8Tn31Ede7PgRjreWtb9dx7zv57DtQyql92tA1rbGCXSRGFO6JqrzmS142VddUDxB8o9TFIZh1O/dzx5tL+GzFFgZnOIW+uqY1du39ReTIKdwTiS8X5j4GW1fC9pXOmPlhPIB15rB3OM7pnTdo5movPZBT6Osrtv10kHvO6sflJ6rQl0g8ULgnCl8uvDiu+i3t8MDER12rqV6dtdv20bGlU+jrgXOPJaNVIzq3UqEvkXihcE8UBTnVB7vL5QGqUlLq59mc1Tz6kVPo68oRXRnRQ4W+ROKNwj3elc+E8S0I8aIBjxcGXwEDL45oTx1g2fpd3PrGYpau282Zx7Rlggp9icQthXu8Kr9h+vU/Qu9ZOuACaNMn4sMv5aZ9WcD9s/Jp0SiVJy8drAqOInFO4R6P8rJh9vVgq5kF06aPqzsgVaW8VECfdk2ZdFxH7prYlxaNNL1RJN4p3OONL7ds3no1we6p5/rio2B7D5Tw0PsrqOc13DGhnwp9iSQYhXu8KcgJvSDJeKF1D0jrCSOui+hQzOffb+G2GUtYv2s/k09UoS+RRKRwjzcNg3rHxgtDJkflhumufcXcPzuf6QsL6ZbuFPo6PlOFvkQSkcI9HpTPiKnfDObcVHHceKIyvbHc1r0HeHfJBn4zqju/G61CXyKJTOEea3nZMPtGZys7goY+rHUWJEXQ5j1FzPx2Pb88uduhQl8tVQ9GJOEp3GPJlwuzrqeiNkzQTVTjidiNU2stb3y9jvtn5bO/uJTRfdvSNa2xgl0kSSjcY6kgh8OLfnkAf0R2RCrn276P299cQs4PW8nq0pIHfq5CXyLJRuEeS8E3Tz31YPxfI1obpqTUz8XPzmPH3oPcP+kYLh3WBY8KfYkkHYV7rPhyYU7AIiTjcYI9QjdPC7bupXOrRqR4PTx4nlPoq1NLFfoSSVYK92gJ3P5u/dfO5tSBhcAidPO0uNTPM5+v4vGPfuC28U6hr+HdVehLJNkp3KPBlwvTJkJJNdvfeVJcv3m6dN0ubpm+mPwNu5kwoD0Tj+3g6vuLSPxSuEfDt/+sPtgxMPgyV8fYX5y7mj/O/o5WjVN56rIhjO3fzrX3FpH4p3CPNF8uLMwO/ZqnnlNqwJsKAy9x5ePKSwUc06E55w7qyJ0T+tG8UT1X3ltEEofCPdJOJ/KLAAANmklEQVQKcg4/1qobDL8O2vZzbaPqnw6U8OB7y0n1erhzYj+Gdm3F0K4qHSBSVyncI6H85mnmyYePo3vrwzlPu7pR9WcrNnPHm0tZv2s/V43oqkJfIqJwd9Xa+bDoVfjmZWcmjPFAm2MqXjdeGPega2PrO/Ye5P7Z+cz4eh092jRh+q+HM6RLS1feW0QSm8K9tsp76Q1bB5USwBlP3/ZD5fNdnO64Y99BPli2id+d1oPfntaD+ikq9CUijrDC3RgzFngc8ALPWWsfCHr9RuCXQAmwBbjKWrvG5bbGH18uTDsLSopwin6F2GCjx2hY+QmUHnRunNZyuuPm3UW89e06fnVyN7qlN2HurafphqmIHKbGcDfGeIEngNOBQmCBMWamtTY/4LRvgCxr7T5jzDXAg8CFkWhwXCnICZjiGCLYvakw4nrnq5Y3Tq21vJ5XyP2z8zlY4uf0fu3omtZYwS4iIYXTcx8KrLTWrgIwxrwGTAIOhbu19tOA8+cBl7nZyLjVsDUY46wu9aQAxhlr93hh8BWVN9ioxTi7b/s+bpuxhC9WbmVo11Y8cO4AFfoSkWqFE+4dAV/A80JgWDXn/wJ4N9QLxpirgasBMjIywmxinPLlltVhD9gSLwJFv8oLfe3cV8wff9afS4ZmqNCXiNQonHAPlSQhd282xlwGZAGnhHrdWvsM8AxAVlZWNTtAxzlfLnz2l7INNsr4S51gP/n3VX/fEVi9dS8ZZYW+HjpvIF1aN6JDi4auvLeIJD9PGOcUAp0DnncC1gefZIwZA9wBnG2trW6tfWLLy4bnT4cfP6l83KXaMMWlfv734x8489HPmfZlAQAndm+tYBeRIxJOz30B0NMY0xVYB1wEVForb4wZBDwNjLXWbna9lbFWPt2xQQuYHapn7k5tmMWFO7ll+mKWb9zDWQM7cPZxKvQlIkenxnC31pYYY64F3seZCvmCtXaZMeY+IM9aOxN4CGgCvF62MnKttfbsCLY7eub+L3x4F1WMRAEGUhrUujbMC1+s5o+z80lvWp9nr8ji9H5ta/V+IlK3hTXP3Vo7B5gTdOzugMdjXG5XfPDlwod3VnOCgawrK8+KOULlpQKO7dScC4/vzNRxfWneUNMbRaR2tEK1OqGKfgXvcXqUOyftKSrmgXeXUz/Fy91n9SMrsxVZmSr0JSLuULhXJ/gGqUt7nH66fDO3v7mETbuL+OXJ3VToS0Rcp3CvSvlN1MZtoHg/dDsFRlxXq5um2/ce5L53lvHWt+vp1bYJ/3fpcAZlqNCXiLhP4R7Mlwvf/BO+eanyAqWVHzvhXgu79hfz8XebuW50T357ag9SU8KZiSoicuQU7uV8ubDoFfj65cobV5crPej05I+w575xl1Po679GdqNrWmO+mHqabpiKSMQp3MEJ9uwJToCHZI64oqO1ltcW+Pjz7O8o9vsZe0w7MtMaK9hFJCoU7uD0yKsKdk/K4UXAarBm216mvrGEr1Zt44RurXjg3GPJVKEvEYkihTuU9cgD67Gb0JUdw1BS6ueSZ+eza38xfz5nABcd31mFvkQk6upuuAfuc9p5KDTr4Gy6MehyaNDsiKc6/rjlJ7qUFfp6+AKn0Ff75qoHIyKxUTfD/dAOSgecYZfe42H3Oue1+U/D5JlhB/vBEj//99lKnvh0JbeN68tVJ3XlhG6tI9h4EZGa1b1w9+XC29eWbY0H+Ivhu7crXj+CWTHf+nZy6/TFrNi0h0nHdeBngzpGqNEiIkemboW7LxdeGFu5DjvAsGtg4YtQWhz2rJjnv1jNn2bn06ZpA56fnMXovir0JSLxo26F+6JXDw92gCbpMPmdsPY5LS8VcFzn5lw0NIOp4/rQrIGmN4pIfKk74Z6XDXkvHH7cU68i0KsJ9d1FxfxlznIa1PPwh7OOYUiXVgzpokJfIhKfkjPcA2fCbMqHvOdh4+LDz0vvDWf/vcbx9Y/yN3HHW0vYsucAvxqpQl8iEv+SL9wPrTYtxpm77g99nvHWGOzbfjrAve/kM3PRevq0a8ozl2cxsHOLiDRbRMRNyRHugT31VZ8FrDatZvekCY/U2GPfU1TCpys2c8OYXlwzqrsKfYlIwkj8cA+cs+5Nga6jqj+/hk021u/cz5vfrOM3o7qTmdaYuVNP0w1TEUk4iR/uBTkVc9ZLi2HlhwEveqDPOKcee7tjq1156vdbXsldywPvLqfUb5kwoD2ZaY0V7CKSkBI/3DNPdnrjthRS6sNJN8EXf4XSEmfO+ojraxx+Wb11L1PfWMz81dsZ0aM1fznnWDJaN4rSBYiIuC/xw73zUOh6Cmz4Bi75t/O8+6iw5qyDU+jrsufms7uomAd/fiznZ3XSTBgRSXiJH+4AjVtDw5YVQV7DnHWAlZv3kNm6MSleD49eeBxdWjeibbMGUWisiEjk1bnpHwdKSnnkw+8Z+1gO075aA8DQrq0U7CKSVJKj5x6mr9fu4Nbpi/lh80+cO6gj56rQl4gkqToT7s9+voo/v/sd7Zs14MUrj+fU3m1i3SQRkYhJ+nD3+y0ej2FwlxZcOiyDW8f2oammN4pIkkvacN+1v5g/zc6nYT0v907qr0JfIlKnJPYNVV8u5DwM21bB/h3Oc+D9ZRs5/ZH/8MbX62hcPwVrqypDICKSnBK35+7LhRfHOzsplbHTzuLhdn/l7ytb0a99M16Ycjz9OzaPYSNFRGIjMcPdlwuf/LFSsANQWky9wrncfOZNXD2yG/W8if0PExGRoxVWuBtjxgKPA17gOWvtA0Gv1wdeAoYA24ALrbUF7ja1zKFCYU49mYoBFw/Gm8qvLp5Mo+49IvLRIiKJosaurTHGCzwBjAP6ARcbY/oFnfYLYIe1tgfwKPA/bjf0kIIcKHFK+lqciu2lFoo6nwyTZ9Ko+4kR+2gRkUQRzrjFUGCltXaVtfYg8BowKeicScC0ssfTgdEmUgVaGrbGlr+zhVI8eOo1oOEZd9ZYckBEpK4IJ9w7Ar6A54Vlx0KeY60tAXYBrd1oYCW+XOzsG8E6uytZ48EzZDKeye8o2EVEAoQT7qF64MFzC8M5B2PM1caYPGNM3pYtW8JpX2UFORjrP/RhHiymRWcFu4hIkHDCvRDoHPC8E7C+qnOMMSlAc2B78BtZa5+x1mZZa7PS09OPvLWZJ4M3YHWpN9U5JiIilYQzW2YB0NMY0xVYB1wEXBJ0zkxgMvAVcB7wiY3EyqHOQ2HKbFj0CmBg4MXqtYuIhFBjuFtrS4wx1wLv40yFfMFau8wYcx+QZ62dCTwPvGyMWYnTY78oYi0Oo1a7iEhdF9Y8d2vtHGBO0LG7Ax4XAee72zQRETlaWsIpIpKEFO4iIklI4S4ikoQU7iIiSUjhLiKShEysNrIwxmwB1hzlt6cBW11sTiLQNdcNuua6oTbX3MVaW+Mq0JiFe20YY/KstVmxbkc06ZrrBl1z3RCNa9awjIhIElK4i4gkoUQN92di3YAY0DXXDbrmuiHi15yQY+4iIlK9RO25i4hINeI63I0xY40xK4wxK40xU0O8Xt8Y86+y1+cbYzKj30p3hXHNNxpj8o0xi40xHxtjusSinW6q6ZoDzjvPGGONMQk/syKcazbGXFD2s15mjHkl2m10Wxi/2xnGmE+NMd+U/X6Pj0U73WKMecEYs9kYs7SK140x5m9l/z0WG2MGu9oAa21cfuGUF/4R6AakAouAfkHn/AZ4quzxRcC/Yt3uKFzzqUCjssfX1IVrLjuvKfA5MA/IinW7o/Bz7gl8A7Qse94m1u2OwjU/A1xT9rgfUBDrdtfymkcCg4GlVbw+HngXZye7E4D5bn5+PPfc42tj7uio8ZqttZ9aa/eVPZ2HszNWIgvn5wxwP/AgUBTNxkVIONf8K+AJa+0OAGvt5ii30W3hXLMFmpU9bs7hO74lFGvt54TYkS7AJOAl65gHtDDGtHfr8+M53ONnY+7oCeeaA/0C5//8iazGazbGDAI6W2tnRbNhERTOz7kX0MsYM9cYM88YMzZqrYuMcK75HuAyY0whzv4R/x2dpsXMkf59PyJhbdYRI65tzJ1Awr4eY8xlQBZwSkRbFHnVXrMxxgM8CkyJVoOiIJyfcwrO0MwonH+d5Rhj+ltrd0a4bZESzjVfDGRbax82xpyIs7tbf2utP/LNi4mI5lc899xd25g7gYRzzRhjxgB3AGdbaw9EqW2RUtM1NwX6A58ZYwpwxiZnJvhN1XB/t9+21hZba1cDK3DCPlGFc82/AP4NYK39CmiAU4MlWYX19/1oxXO4H9qY2xiTinPDdGbQOeUbc0MkN+aOnhqvuWyI4mmcYE/0cVio4ZqttbustWnW2kxrbSbOfYazrbV5sWmuK8L53X4L5+Y5xpg0nGGaVVFtpbvCuea1wGgAY0xfnHDfEtVWRtdM4IqyWTMnALustRtce/dY31Gu4W7zeOB7nLvsd5Qduw/nLzc4P/zXgZVALtAt1m2OwjV/BGwCvi37mhnrNkf6moPO/YwEny0T5s/ZAI8A+cAS4KJYtzkK19wPmIszk+Zb4IxYt7mW1/sqsAEoxuml/wL4NfDrgJ/xE2X/PZa4/XutFaoiIkkonodlRETkKCncRUSSkMJdRCQJKdxFRJKQwl1EJAkp3EVEkpDCXUQkCSncRUSS0P8DvRbGw8DFP7cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-94c61ad12502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# calculate precision-recall AUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# calculate average precision score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# predict class values\n",
    "yClass = model.predict(X_test_scaled)\n",
    "# calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "# calculate F1 score\n",
    "f1 = f1_score(y_test, yClass)\n",
    "# calculate precision-recall AUC\n",
    "auc = auc(recall, precision)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(y_test, probs)\n",
    "print('f1=%.3f auc=%.3f ap=%.3f' % (f1, auc, ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0.5, 0.5], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "pyplot.plot(recall, precision, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search / Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies from sklearn, build model using \"rbf\" kernel for the support vector classifier and bring in\n",
    "# hyperparameters \"C\" and \"gamma\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "modelGS = SVC(kernel='rbf')\n",
    "param_grid = {'C': [.01, 1, 10, 100, 1000],\n",
    "              'gamma': [0.0001, 0.001, 0.01,]}\n",
    "grid = GridSearchCV(modelGS, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "[CV] C=0.01, gamma=0.0001 ............................................\n",
      "[CV] ................ C=0.01, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.0001 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.01, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.0001 ............................................\n",
      "[CV] ................ C=0.01, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................. C=0.01, gamma=0.001, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ................. C=0.01, gamma=0.001, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ................. C=0.01, gamma=0.001, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .................. C=0.01, gamma=0.01, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .................. C=0.01, gamma=0.01, score=0.536, total=   0.1s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .................. C=0.01, gamma=0.01, score=0.536, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.543, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.536, total=   0.1s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.538, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.560, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.547, total=   0.1s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.556, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.543, total=   0.2s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.536, total=   0.1s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.538, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.564, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.545, total=   0.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.553, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.556, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.550, total=   0.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] .................... C=10, gamma=0.01, score=0.563, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.563, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.544, total=   0.1s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] ................. C=100, gamma=0.0001, score=0.555, total=   0.1s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.559, total=   0.1s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.548, total=   0.1s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] .................. C=100, gamma=0.001, score=0.555, total=   0.1s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.561, total=   0.1s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.547, total=   0.1s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................... C=100, gamma=0.01, score=0.568, total=   0.2s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ................ C=1000, gamma=0.0001, score=0.562, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ................ C=1000, gamma=0.0001, score=0.544, total=   0.1s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ................ C=1000, gamma=0.0001, score=0.555, total=   0.1s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] ................. C=1000, gamma=0.001, score=0.554, total=   0.1s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] ................. C=1000, gamma=0.001, score=0.548, total=   0.1s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] ................. C=1000, gamma=0.001, score=0.560, total=   0.1s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] .................. C=1000, gamma=0.01, score=0.564, total=   0.2s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] .................. C=1000, gamma=0.01, score=0.558, total=   0.2s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] .................. C=1000, gamma=0.01, score=0.567, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.01, 1, 10, 100, 1000],\n",
       "                         'gamma': [0.0001, 0.001, 0.01]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.01}\n",
      "0.563091964558509\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC - best parameters and score for the data\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier to the data\n",
    "clf = clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.532967032967033\n"
     ]
    }
   ],
   "source": [
    "# Calculate the R2 score for the test data\n",
    "r2 = clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576923076923077"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create, fit, and score a Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=500)\n",
    "rf = rf.fit(X_train_scaled, y_train)\n",
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5576923076923077\n"
     ]
    }
   ],
   "source": [
    "# validating scores\n",
    "from sklearn import metrics\n",
    "prediction=rf.predict(X_test_scaled)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters Set for decision tree\n",
    "params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
    "          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
    "          'random_state':[123]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyper Parameters: {'max_features': 'auto', 'min_samples_leaf': 11, 'min_samples_split': 2, 'random_state': 123}\n",
      "Accuracy: 0.5686813186813187\n"
     ]
    }
   ],
   "source": [
    "#Making models with hyper parameters sets\n",
    "model1 = GridSearchCV(rf, param_grid=params, n_jobs=-1)\n",
    "#Learning\n",
    "model1.fit(X_train_scaled,y_train)\n",
    "#The best hyper parameters set\n",
    "print(\"Best Hyper Parameters:\",model1.best_params_)\n",
    "#Prediction\n",
    "prediction=model1.predict(X_test_scaled)\n",
    "#evaluation(Accuracy)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10020941 0.25455084 0.2154515  0.42978825]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
